{"podcast_details": {"podcast_title": "The AI Breakdown: Daily Artificial Intelligence News and Discussions", "episode_title": "The Future of AI Music: YouTube and Universal Partner", "episode_image": "https://megaphone.imgix.net/podcasts/9ad36894-20f2-11ee-9d6c-d76aa9b66d23/image/BITCOIN_BUILDERS_3.png?ixlib=rails-4.3.1&max-w=3000&max-h=3000&fit=crop&auto=format,compress", "episode_transcript": " Today on the AI Breakdown, we're talking about YouTube's new partnership with Universal Music Group around AI music. Before that on the brief, Mid Journey releases a new in-painting feature, Snapchat getting ready to launch AI Dreams, and an AI stock market update. The AI Breakdown is a daily podcast and video about the most important news and discussions in AI. Go to breakdown.network for more information about our Discord, our newsletter, and our YouTube. Welcome back to the AI Breakdown Brief, all the AI headline news you need in around 5 minutes. We start today with the announcement of a feature that has been much anticipated, and that is in-painting in Mid Journey. Now in-painting is basically the ability to change a specific portion of an image created with AI to be different in some way. This was a feature that Adobe launched a couple months ago to much fanfare. So imagine for example in Mid Journey you've created an image of a woman staring directly at camera in an illustrated or animation style, and you want to place that woman in a bunch of different settings. Using in-painting you'd be able to select the specific part of the image that you wanted to change, in this case the background, and prompt the system to change that aspect with text just like you would prompt to create the image in the first place. It makes it easy to do things like change the clothes someone is wearing, or to give them sunglasses. And while right now people are mostly just creatively experimenting, there are some more business use cases as well. For example, imagine an interior designer being able to switch around furniture or color palettes in a single environment. Overall, this is the type of tool and feature set that will, I believe, become so essential to the way that people use Mid Journey that it'll be hard to remember a time before it actually existed. Speaking of features, Snapchat is expanding a new feature in its generative AI suite that it is calling Dreams. TechCrunch writes, With the company's forthcoming generative AI feature called Dreams, Snap will again experiment with AI images. But soon those images may contain you and your friends in imaginative backgrounds. Snapchat imagines Dreams as a way to use AI-generated selfies to place pictures of you in fantastical places and scenarios. So far, these features haven't been confirmed by Snapchat itself. The latest report comes from findings from app researcher and developer Steve Moser, and earlier in the year, frequent mobile feature leaker Alessandro Pelluzzi also shared an image of what seemed to be this Dreams feature. In that image, it was placed very prominently between camera roll and stories. And the prompt was, Upload several selfies to create your dreams and generate fantastical snaps of yourself. Now, not all of Snapchat's experiments with AI have gone particularly well. Remember last week we were talking about how its My AI Bot kind of creepily posted a story, even though it wasn't supposed to be able to do so. It does seem, however, like the idea of putting users in fun settings with their selfies is pretty well aligned with the core entertaining experience of Snapchat. It might be something that people really respond to. Now last week, we also got word of a new AI social app called Be Fake. The idea behind this app was to lean into the unreality of an AI world and have the core experience being sharing photos of oneself that were AI modified. So changing your hair, giving you costumes, giving you makeup, placing you in new fantastical settings. There are of course tons of apps that have this sort of feature suite of using text prompts to modify images of yourself, but putting that as the foundational experience of a social media network is something a little bit new. Rowan Chung wrote, Kristin Garcia Dumont, ex-MachineZone CEO, has founded a new social media app called Be Fake to redefine social media. The app lets users snap fantasy versions of themselves using AI-generated images. It allows users to express creativity beyond just selfies by submitting text prompts to generate visuals. CEO Dumont sees it as a more authentic self-expression versus the pressure of real pictures. The most creative faux identities gain traction in the app's community, with users able to share images from prompts and react to their favorites. The founder of Be Fake is no joke with some of the top-grossing mobile games globally under her belt. I'll be watching this app closely as it might play a pivotal role in the widespread integration of AI into social media. I do think it's a super interesting premise to try to break from the pressure of perfection that social media puts on, to just lean into the hyper-modification of AI in an environment in which everyone understands that that's what's happening. It's not that it doesn't come with its own issues, but it does at least theoretically solve some of the issues of the last generation of social media as well. It's also interesting in light of the news that Meta has confirmed that an off-switch for algorithmic content curation is coming to Facebook and Instagram in Europe. TechCrunch writes, Meta has confirmed that non-personalized content feeds are incoming on Facebook and Instagram in the European Union ahead of the August 25th deadline for compliance with the bloc's rebooted digital rulebook, the Digital Services Act. The DSA requires larger platforms and search engines to provide users in the region with the ability to switch off AI-driven personalization. Instead, content could be ordered and displayed chronologically, such as based on the time a post was made or ranked by local popularity. Finally, we close on a couple stories from markets. Chipmaker ARM is going public, and as Yahoo Finance puts it, their valuation hinges on how much AI hype investors price in. Basically, what investors are looking at is how much of a premium is being put on this company because of its association with AI. Yahoo Finance writes, Bloomberg has previously reported that ARM was aiming for valuations between $60 and $70 billion, as the chip designer tries to cash in on an investor's frenzy for stocks that can benefit from the rise in artificial intelligence. Those kinds of levels are high compared with the valuations that investors have awarded smaller ARM competitors, using the price-to-sales ratio of those public companies for ARM would imply a value between $32 billion and $43 billion for the chip designer. Meanwhile, another company that is already trading has received a bump from its use of AI. Zoom got a little popped yesterday as the CEO said that the company plans to develop and continue to deploy new AI tools. As CNN Business puts it, Zoom's founder and chief executive officer, Eric Yuan, also touted the company's rollout of recent AI features on a conference call with investors. Yuan said that the company's aggressive roadmap when it comes to artificial intelligence is, quote, aimed at empowering our customers to work smarter and serve their customers better. Now, of course, this is the same company that just faced huge backlash over changing their terms of service to seemingly allow themselves to train their AI models on users' proprietary conversations. But they've now done a 180 and said that that would never be the case, and even shifted and stopped letting people even opt into that. Anyways, friends, that is going to do it for today's AI Breakdown Brief. If you're enjoying this content and you haven't yet subscribed, I would so appreciate it if you would do so. Thanks, as always, for listening or watching, and I'll be back soon with the main AI Breakdown. Welcome back to the AI Breakdown. Today we are talking about AI in the context of the music industry. Now, music has, for 25 years now, had a really interesting place in the history of new technologies. It was one of the first industries to be well and truly disrupted by technology when Napster came out in 1999, yet at the same time the legal battles that ensued in many ways better prepared the incumbents to fight legally for continued power in the context of the internet era than was the case for many other peer industries. All throughout Web 2, record labels have remained dominant players in the space because the big startups that dealt with streaming music, notably Spotify, bent the knee and continued to perpetuate the old power system. Today's show isn't meant to make an argument about whether that's good or bad, but simply to point out that it is the case. Fast forward to April of this year. On April 4th, a song called Heart on My Sleeve was released first on TikTok and then on all the major streaming services using vocals that sounded like Drake and the Weeknd. In the first couple days after this song came out, it was absolutely everywhere. Millions and millions and millions of people streamed, saw, and heard this song. Now, of course, Drake and the Weeknd weren't actually on it. The vocals were synthesized voices generated by artificial intelligence. The anonymous producer Ghostwriter 977 wasn't trying to hide that fact, but it still awoke the slumbering giant of the music industry and Universal Music Group went out of their way to get the song taken down everywhere they possibly could. Now interestingly, as The Verge wrote at the time, getting it taken down wasn't as clear-cut as it might seem. As they wrote, This is where it gets fascinatingly weedsy and probably existentially difficult for Google. To issue a copyright takedown to YouTube, you need to have a copyright on something. Boomin's Heart on My Sleeve is an original song, UMG doesn't own it. It's not a copy of any song in the label's catalog. Now ultimately what allowed YouTube to comply with UMG's claim was the Metro Boomin producer tag at the start of the song, which they all agreed was an unauthorized sample. As The Verge summed up, If Ghostwriter 977 uploads Heart on My Sleeve without the Metro Boomin tag, they will kick off a copyright war that pits the future of Google against the future of YouTube. Now of course, alternative to the approach of fighting everything in a legal battle, another strategy could be for the big labels to embrace the reality of AI music and to try to capture a piece of that action. For example, Product Hunt founder Ryan Hoover suggested an AI version of Spotify that would host AI-generated music explicitly. Anyone could submit songs, the best songs would rise to the top, and then artists would get cut in on the value of the streams. Artists who didn't want to participate would be able to opt out, and the advancement of AI music could continue while the current industry gets their piece of the pie. All of this is what made it interesting when last week the Financial Times reported that Google and Universal Music Group were in discussions on how to license their artists' voices for presumably some type of generative AI content creation. The FT wrote, Google and Universal Music are in talks to license artists' melodies and voices for songs generated by artificial intelligence as the music business tries to monetize one of its biggest threats. The discussions, confirmed by four people familiar with the matter, aim to strike a partnership for an industry that is grappling with the implications of new AI technology. Now there weren't very many details given in this piece. The FT said that these talks were at a very early stage, that no specific product launch was right around the corner, but that the idea or the goal was to create a platform just like Ryan had suggested, where fans could create these tracks legitimately and legally, and where the owners of the copyrights would get paid for that action. In addition to Universal, the FT reported that Google was also talking to Warner Music. Fast forward to this week, and YouTube's official blog has released a long post called Our Principles for Partnering with the Music Industry on AI Technology. AI is here, they say, and we will embrace it responsibly together with our music partners. The piece reads, We're working closely with our music partners, including Universal Music Group, to develop an AI framework to help us work towards our common goals. YouTube says they have three fundamental AI principles to quote, enhance music's unique creative expression, while also protecting music artists and the integrity of their work. Article number one, they say, AI is here, and we will embrace it responsibly together with our music partners. YouTube points out here that this is just not something that can be avoided. They write that this year alone, there have already been 1.7 million views of videos related to generative AI tools on YouTube, and that effectively, sticking their heads in the sand collectively was not going to accomplish anything. Now one specific initiative that falls out of this is that they're creating an AI music incubator with UMG as a partner. YouTube CEO Neil Mohan said, The incubator will help YouTube's approach as we work with some of music's most innovative artists, songwriters, and producers across the industry. Now candidly, it's not super clear exactly what this incubator is going to do. They point to a group of UMG talent who are going to be involved, including Anita, Max Richter, Roseanne Cash, Ryan Tedder of OneRepublic. But the way they describe what they'll actually be doing is, this talented group will help gather insights on generative AI experiments and research that are being developed at YouTube. Working together, we will better understand how these technologies can be most valuable for artists and fans, how they can enhance creativity, and where we can seek to solve critical issues for the future. So cool, but not exactly sure what they're going to do, right? Principle number two, AI is ushering in a new age of creative expression, but it must include appropriate protections and unlock opportunities for music partners who decide to participate. And again, details on what YouTube is actually going to do are scant, but it seems like the outcome of this principle is going to be an update on Content ID, which they call our best-in-class rights management technology. They write, a new era of generated content is here, and it gives us an opportunity to reimagine and evolve again. Principle three, we've built an industry-leading trust and safety organization and content policies. We will scale those to meet the challenges of AI. And in this section, they basically say that they're going to need to use AI technology to help keep the platform safe from AI technology. They write, the limitless power of generative AI demands a thoughtful approach that maps to the expansive boundaries of creative expression. Generative AI systems may amplify current challenges like trademark and copyright abuse, misinformation, spam, and more. But AI can also be used to identify the sort of content and will continue to invest in the AI power technology that helps us protect our community of viewers, creators, artists, and songwriters. Now, in addition to this note from the CEO of YouTube, they also published a note from Sir Lucian Grange, the chairman and CEO of UMG. That post was called an art-centric approach to AI innovation. AI will amplify human imagination and enrich musical creativity in extraordinary new ways and will need to strike the balance. Grange kicks off his piece comparing generative AI to the uproar around the first samplers. He said, I was still a young talent scout in 1980s London when Fairlight CMI, the world's first commercially available sampler, hit the scene. Almost immediately, some decried this digital manipulation as artificial. I was in the other camp, curious at first, then enthusiastic about the musical creativity it made possible. Over the next decade, as more affordable options such as MIDI and Pro Tools came on the market, just about everyone who was interested could use digital synthesizers and samplers to help create the sound they wanted. But as big an impact as that technology had on music, I sense even greater potential in generative AI to inspire and empower a new generation of talent. At the same time, he says he's concerned about digital manipulation, appropriation, and misattribution. In his post, we get perhaps maybe a little bit more information about what the incubator will do. What effectively makes it seem like this group of UMG talent will be the front lines to experiment with new AI-related tools that YouTube and Google are working on. They'll be able to offer feedback and hopefully improve those tools as well as making them feel more safe for other artists to experiment with as well. Now the timing of this announcement is kind of interesting. On the one hand, it's clear that they have been working on this for some time. You don't get all these artists to agree to something like this incubator, as vaguely defined as it is here, without going through a lot of layers of management and back and forth. They don't get to the point where they can announce it in a blog post like this. At the same time, the details are so scant around what this partnership entails. It feels somewhat like it was rushed or at least it felt like there was pressure to get something out, perhaps in response to the leaks last week of this sort of thing happening. Whether it's rushed or not though, I'm glad to see it happening. I think AI-generated music is absolutely, totally inevitable. I think the tools are just going to be too easy and available for it not to be a thing that people do. I think that Net-Net, giving people the ability to opt in to a brave new frontier and to allow artists to monetize their voice and their likeness in new ways, is a better approach than what would be a never-ending game of Whack-a-Mole to try to stamp out every heart on my sleeve that gets pushed to YouTube. Mostly I'm just excited to see what people create, and I'm glad that it seems like there's going to be better, more aboveboard resources for them to do so. Anyways guys, that is going to do it for today's AI Breakdown. Thanks as always for listening or watching, and until next time, peace."}, "podcast_summary": "In today's AI Breakdown, we have several major news headlines to cover. First, YouTube has announced a new partnership with Universal Music Group that focuses on AI music. The details of the partnership are still unclear, but it seems that Google and UMG are discussing licensing artists' melodies and voices for songs generated by artificial intelligence. This is an effort to monetize AI music and embrace the new age of creative expression while protecting the integrity of artists' work.\n\nMoving on, the podcast discusses the new features and developments in AI technology. Mid Journey has released a much-anticipated in-painting feature, which allows users to change specific portions of an image created with AI. This feature has both creative and business use cases, such as easily changing backgrounds or rearranging furniture. Snapchat is also expanding its generative AI suite with a feature called Dreams, which uses AI-generated selfies to place users in imaginative backgrounds. While these features have not been confirmed by Snapchat, they align with the fun and entertaining experience that the platform offers.\n\nAdditionally, a new AI social app called Be Fake has been launched, allowing users to share AI-modified photos of themselves. The app aims to provide a more authentic self-expression by embracing the hyper-modification of AI in a social media environment. This app could potentially play a pivotal role in integrating AI into social media and breaking away from the pressure of perfection.\n\nIn other news, Meta has confirmed that an off-switch for algorithmic content curation is coming to Facebook and Instagram in Europe. This move complies with the Digital Services Act, which requires larger platforms to provide users with the ability to switch off AI-driven personalization. This update will allow users to see content chronologically or based on local popularity, providing more control and transparency.\n\nFinally, in the market news, chipmaker ARM is going public, and its valuation will depend on how much investors price in the hype around AI. Investors are looking at the company's association with AI and its potential in the market. Another company, Zoom, has received a boost due to its AI tools, with its CEO announcing plans to develop and deploy new AI tools to empower customers in working smarter and serving their own customers better.\n\nThat wraps up today's AI Breakdown summary. Tune in next time for more updates and discussions on the latest news in AI technology. Thank you for reading and stay tuned for the next newsletter.\n\n", "podcast_guest": "None", "podcast_highlights": "- Mid Journey releases new in-painting feature for image editing\n- Snapchat expanding new generative AI feature called Dreams for AI-generated selfies\n- AI social app called Be Fake allows users to modify AI-generated images of themselves\n- Meta confirms off-switch for algorithmic content curation on Facebook and Instagram in Europe\n- YouTube partners with Universal Music Group to develop AI framework for AI-generated music\n- Google and Universal Music Group in talks to license artists' melodies and voices for AI-generated songs\n- YouTube creates AI music incubator with UMG to experiment with generative AI tools\n- UMG talent including Anita, Max Richter, Roseanne Cash, Ryan Tedder involved in AI experiments\n- YouTube and UMG aim to strike a balance between AI creativity and artist protection"}